# -*- coding: utf-8 -*-
import os
import time
import random
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import re
import sys

# è§£å†³ Windows ç»ˆç«¯ç¼–ç é—®é¢˜
sys.stdout.reconfigure(encoding='utf-8')

# ----------------- é…ç½®å‚æ•° -----------------
BASE_URL = "https://digitallibrary.un.org"
VOTING_PAGE_URL_TEMPLATE = "https://digitallibrary.un.org/search?cc=Voting+Data&c=Voting+Data&ln=en&fct__2=Security+Council&jrec={}&rg=50"
DOWNLOAD_DIR = "./UN_Voting_PDFs"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.9",
    "Referer": BASE_URL,
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
}

# ----------------- é‡è¯•é…ç½® -----------------
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504]
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session = requests.Session()
session.mount("https://", adapter)

# ----------------- è·å–æ‰€æœ‰è¡¨å†³è®°å½• -----------------
def get_voting_records(max_pages=1):
    """
    çˆ¬å–è¡¨å†³è®°å½•é¦–é¡µï¼Œè·å–æ¯ä¸ªä¼šè®®è¯¦æƒ…é¡µçš„ URL
    """
    voting_records = []
    for page_number in range(max_pages):
        page_url = VOTING_PAGE_URL_TEMPLATE.format(page_number * 50 + 1)
        print(f"ğŸ“¥ è·å–é¡µé¢: {page_url}")
        response = session.get(page_url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(response.text, "html.parser")

        # è§£æä¼šè®®è¯¦æƒ…é¡µé“¾æ¥
        record_links = soup.find_all("div", class_="moreinfo")
        if not record_links:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è¡¨å†³è®°å½•ï¼Œå¯èƒ½ HTML ç»“æ„å‘ç”Ÿå˜åŒ–ï¼")
            break  # æ²¡æœ‰æ•°æ®ï¼Œç»ˆæ­¢å¾ªç¯

        for link in record_links:
            detailed_link_tag = link.find("a", class_="moreinfo", href=True)
            if detailed_link_tag and "record" in detailed_link_tag["href"]:
                record_url = BASE_URL + detailed_link_tag["href"]
                voting_records.append(record_url)

        print(f"âœ… è·å–åˆ° {len(record_links)} æ¡è¡¨å†³è®°å½•")
        time.sleep(random.uniform(1, 3))  # é¿å…è¯·æ±‚è¿‡å¿«

    return voting_records

# ----------------- è§£æä¼šè®®è®°å½•é“¾æ¥ -----------------
def get_meeting_record(voting_url):
    """
    è§£æè¡¨å†³è®°å½•é¡µé¢ï¼Œæ‰¾åˆ°ä¼šè®®è®°å½•çš„è¯¦æƒ…é¡µ URL
    """
    response = session.get(voting_url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(response.text, "html.parser")

    # æŸ¥æ‰¾æ‰€æœ‰ metadata-row
    for row in soup.find_all("div", class_="metadata-row"):
        title_tag = row.find("span", class_="title")
        if title_tag and "Meeting record" in title_tag.text:
            value_tag = row.find("span", class_="value")
            if value_tag:
                meeting_record_link = value_tag.find("a", href=True)
                if meeting_record_link:
                    return meeting_record_link["href"]

    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä¿å­˜ HTML ä¾›è°ƒè¯•
    clean_filename = re.sub(r"[^a-zA-Z0-9_-]", "_", voting_url.split("/")[-1]) + ".html"
    debug_filename = f"debug_meeting_record_{clean_filename}"

    with open(debug_filename, "w", encoding="utf-8") as f:
        f.write(soup.prettify())
    print(f"âš ï¸ æœªæ‰¾åˆ°ä¼šè®®è®°å½•é¡µé¢ï¼Œå·²ä¿å­˜ HTML ä¾›è°ƒè¯•: {debug_filename}")

    return None

# ----------------- è§£æä¼šè®®è®°å½• PDF -----------------
def get_pdf_link(meeting_record_url):
    """
    è§£æä¼šè®®è®°å½•é¡µé¢ï¼Œæ‰¾åˆ°è‹±æ–‡ç‰ˆ PDF çš„ä¸‹è½½é“¾æ¥
    """
    response = session.get(meeting_record_url, headers=HEADERS, timeout=15)
    soup = BeautifulSoup(response.text, "html.parser")

    # æ‰¾åˆ°æ‰€æœ‰ä¸‹è½½é“¾æ¥ï¼Œç­›é€‰ English ç‰ˆ
    for link in soup.find_all("a", href=True):
        if "-EN.pdf" in link["href"]:  # åªæŠ“å–è‹±æ–‡ç‰ˆ PDF
            return BASE_URL + link["href"]

    return None

# ----------------- ä¸‹è½½ PDF -----------------
def download_pdf(pdf_url, filename):
    """
    ä¸‹è½½ PDF æ–‡ä»¶ï¼Œå¹¶å­˜å‚¨åˆ°æœ¬åœ°
    """
    try:
        filepath = os.path.join(DOWNLOAD_DIR, filename)
        if os.path.exists(filepath):
            print(f"ğŸŸ¢ æ–‡ä»¶å·²å­˜åœ¨: {filename}")
            return True

        with session.get(pdf_url, headers=HEADERS, stream=True, timeout=30) as r:
            r.raise_for_status()
            total_size = int(r.headers.get('content-length', 0))

            with open(filepath, "wb") as f:
                with tqdm(
                    total=total_size, unit='B',
                    unit_scale=True, desc=filename[:20],
                    bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]"
                ) as pbar:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return False

# ----------------- ç»„åˆæ‰€æœ‰æ­¥éª¤ -----------------
def main():
    """
    ä¸»æµç¨‹ï¼šè·å–è¡¨å†³è®°å½• -> è¿›å…¥ä¼šè®®è®°å½• -> ä¸‹è½½ PDF
    """
    print("ğŸ“Œ å¼€å§‹çˆ¬å–è”åˆå›½å®‰ç†ä¼šè¡¨å†³è®°å½•")

    # åªçˆ¬å–å‰ 1 é¡µï¼ˆ50 æ¡è®°å½•ï¼‰
    voting_records = get_voting_records(max_pages=1)

    for voting_url in tqdm(voting_records, desc="ğŸ“Š æ­£åœ¨å¤„ç†è¡¨å†³è®°å½•"):
        print(f"\nğŸ” å¤„ç†è¡¨å†³è®°å½•: {voting_url}")

        # è·å–ä¼šè®®è®°å½•é¡µé¢ URL
        meeting_record_url = get_meeting_record(voting_url)
        if not meeting_record_url:
            print(f"âš ï¸ æœªæ‰¾åˆ°ä¼šè®®è®°å½•é¡µé¢ï¼Œè·³è¿‡ {voting_url}")
            continue

        print(f"ğŸ“‘ ä¼šè®®è®°å½•é¡µé¢: {meeting_record_url}")

        # è·å– PDF ä¸‹è½½é“¾æ¥
        pdf_url = get_pdf_link(meeting_record_url)
        if not pdf_url:
            print(f"âš ï¸ æœªæ‰¾åˆ°è‹±æ–‡ç‰ˆ PDFï¼Œè·³è¿‡ {meeting_record_url}")
            continue

        print(f"ğŸ“„ PDF ä¸‹è½½é“¾æ¥: {pdf_url}")

        # ä¸‹è½½ PDF
        resolution_number = voting_url.split("/")[-1].split("?")[0]  # è§£æ URL è·å–ç¼–å·
        filename = f"{resolution_number}.pdf"
        if download_pdf(pdf_url, filename):
            print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename}")
        else:
            print("âŒ ä¸‹è½½å¤±è´¥")

        time.sleep(random.uniform(2, 5))  # é¿å…è¯·æ±‚è¿‡å¿«

if __name__ == "__main__":
    main()
