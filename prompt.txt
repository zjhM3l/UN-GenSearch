接下来我需要你进行一些文字内容的工作，首先我希望你对我们的项目有一个整体的完整的了解，接下来我会告诉你我们的项目的整体要求，以及我们预想的预计的进展方案和计划。需要你记住，因为后续任务斗鱼这个相关
项目要求如下：
总体上我们的任务是针对专业领域的 LLM 优化，并且计划使用 RAG（Retrieval-Augmented Generation）策略来提升信息检索能力。
分成三个阶段分别是Data crawling，Developping a Retriever以及 An application to Chatbot。
首先第一个任务就是根据我们的选题选定一个网站进行数据爬取相关工作，没有什么好说的。
任务二Retriever，这部分需要我们Corpus Creating，然后Retriever，Focus: Indexing + Searching Documents，Flexible Text Embedding models, corpus, and
scoring functions。然后就是Text Embedding Models。
任务三就需要我们Application to Chatbot，基本就是query过task2的retriever然后返回最高几个relevant docs给llm整理输出，从而优化针对特定领域不能很好回答的问题。

上述就是整体要求，针对我们的项目，我需要你知道的是，首先我们选择的领域是优化 LLM 在法律、国际时事、伦理领域的理解和回答，从而消除主观性和片面性。
我们选择的数据集为联合国数字图书馆（包括联合国会议投票与发言记录与联合国决议文件）
包含联合国大会（General Assembly）发言人记录，覆盖 第1-78届会议。
retrieve阶段我们预计使用FAISS本地部署运行，检索分为关键词匹配（BM25） → 适用于法律、法规等结构化文本。以及语义检索（Embedding + FAISS） → 适用于长文本 & 自然语言查询。分别处理会议文件和发言表决记录。
并且用deepseekR1的向量 进行语义匹配，提高相关性。
然后下一块是Text Embedding（文本向量化）任务，这块我会本地部署DeepSeek R1（7b）进行，
使用FP16 或 4-bit 量化（减少 VRAM 占用，提高推理速度）。
使用批量推理（batch processing）（减少 I/O 开销）。
提前清理文本（去掉 HTML、特殊符号，公共文件头等，提高处理效率）。
然后task3的Chat Application Binding（与 LLM 交互）计划本地部署：使用 DeepSeek R1 本地运行（保证安全性）
流程暂时设定为
用户输入 → 检索最相关文档（Retrieve）
选出前 10 个相关文档
将这些文档作为 Prompt 传入 LLM
让 LLM 生成最终答案
最后考虑绑定 Chat UI，让他变成一个Web 端搜索引擎，考虑使用Gradio快速测试

上述就是关于我们项目的总览要求和我们的预期，请你记住他们，并且理解他们，后面我们接下来的任务与这个相关。

我现在在overleaf上用latex写我们这个项目的Proposal (for task 3)意思就是说是针对所有全部三个task（Task 1: Data crawling，Task 2: Developping a Retriever， Task 3: An application to Chatbot）的，然后现在是一个纯模板（里面的内容和我们没有任何关系都需要针对性改动），模板整体内容如下：
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.75in]{geometry}

\begin{document}
	\begin{center}
    
    	% MAKE SURE YOU TAKE OUT THE SQUARE BRACKETS
    
		\LARGE{\textbf{UN-RAG Proposal}} \\
        \vspace{1em}
        \normalsize\textbf{Jiahe Zhang} \\
        \normalsize{jz185@rice.edu} \\
        \vspace{1em}
        \normalsize{Hongji Wang} \\
        \normalsize{hw100@rice.edu} \\
        \vspace{1em}  
	\end{center}
\begin{normalsize}
    
    	\section{section1:}
        
       
\end{normalsize}
  
\end{document}


然后现在首先，我会发给你老师的相关要求，然后我需要你给我们生成一个大致框架，这个框架包含了所有应该有的部分，但是不需要在里面写内容，只需要用注释标注出来这个部分下面应该包含什么样的内容就行。就是那种概览指导性的说明。这是老师对proposal的相关说明：
Write 2 pages. When writing the proposal you should try to
answer the following questions:
– What is the problem you are solving?
– What data will you use?
– What work do you plan to do the project?
– Which algorithms/techniques/models you plan to
use/develop? Be as specific as you can!
– Who will evaluate your method? How will you test it? How
will you measure success?
– What do you expect to submit/accomplish by the end of
the semester?

好的接下来我们一部分一部分来，首先是这部分：
\begin{normalsize}
    \section{Introduction} 
    % - Briefly introduce the problem domain and why it matters.
    % - Provide motivation for improving LLMs in the legal, international affairs, and ethics domains.
    % - Mention the use of Retrieval-Augmented Generation (RAG) as a solution.
    % - Summarize the three tasks (data crawling, retriever, chatbot application)

请你结合我上述提到的相关内容：
上述就是整体要求，针对我们的项目，我需要你知道的是，首先我们选择的领域是优化 LLM 在法律、国际时事、伦理领域的理解和回答，从而消除主观性和片面性。
我们选择的数据集为联合国数字图书馆（包括联合国会议投票与发言记录与联合国决议文件）
包含联合国大会（General Assembly）发言人记录，覆盖 第1-78届会议。
retrieve阶段我们预计使用FAISS本地部署运行，检索分为关键词匹配（BM25） → 适用于法律、法规等结构化文本。以及语义检索（Embedding + FAISS） → 适用于长文本 & 自然语言查询。分别处理会议文件和发言表决记录。
并且用deepseekR1的向量 进行语义匹配，提高相关性。
然后下一块是Text Embedding（文本向量化）任务，这块我会本地部署DeepSeek R1（7b）进行，
使用FP16 或 4-bit 量化（减少 VRAM 占用，提高推理速度）。
使用批量推理（batch processing）（减少 I/O 开销）。
提前清理文本（去掉 HTML、特殊符号，公共文件头等，提高处理效率）。
然后task3的Chat Application Binding（与 LLM 交互）计划本地部署：使用 DeepSeek R1 本地运行（保证安全性）
流程暂时设定为
用户输入 → 检索最相关文档（Retrieve）
选出前 10 个相关文档
将这些文档作为 Prompt 传入 LLM
让 LLM 生成最终答案
最后考虑绑定 Chat UI，让他变成一个Web 端搜索引擎，考虑使用Gradio快速测试

尽量简短


接下来是
\section{Problem Statement} 
    % - Define the specific problem you are solving.
    % - Explain the limitations of current LLMs in legal and international contexts.
    % - Highlight the need for accurate and unbiased retrieval to assist LLMs.
这块除此之外我还写了一些东西作为参考如下：
## **1. LLM 在法律与国际决议问题上的局限性**

### **1.1 信息不完整与选择性回答**
通过测试 18 个主流 LLM（包括 ChatGPT、Claude 3、Gemini 1.5、Mistral-Large、Llama 3-70B 等(注，deepseekr1在几乎全部的议题上回复准确率和相关表达完全符合联合国会议相关记录及事实证明，此处不再过多提及，但是我们确实也针对deepseek进行了实验)），我们发现：
- 在询问"巴勒斯坦是否曾被提供完全自治国家地位"时：
  - **ChatGPT (GPT-4 Turbo O1Pro)** 回答："是的，历史上存在多个提案"，随后给出长达 1200 字的解释，但包含明显事实错误：
    - 错误声称"1948 年联合国分治方案确立了巴勒斯坦主权"（实际该方案被阿拉伯国家拒绝）
    - 错误将 2000 年《戴维营协议》描述为"已实施的自治方案"（实际未达成最终协议）
  - 根据联合国 242/338 号决议及国际法院咨询意见，**过去 76 年（非三百年）** 从未形成具有完全主权的巴勒斯坦国

- **其他典型示例**：
  ```markdown
  | 提问内容                        | Claude 3 回应                         | 事实核查（联合国记录）              |
  |---------------------------------|--------------------------------------|------------------------------------|
  | "俄罗斯在2022年乌克兰决议中的投票" | "该决议涉及人道主义问题，部分国家弃权"  | 明确记录俄罗斯投反对票（1/5常任理事国反对）|
  | "以色列定居点合法性"            | "国际社会存在不同观点"                | 联合国安理会2334号决议明确认定违法  |
  ```

### **1.2 信息来源的局限性**
#### **语言偏向性实证**
通过对比 2023 年联合国气候峰会决议的 LLM 响应：
- 英文提问时，**83% 的 LLM** 优先引用《纽约时报》《卫报》报道
- 中文/阿拉伯语提问时，**仅 12% 的 LLM** 会引用《新华社》《半岛电视台》的报道

#### **数据时效性问题**
- 对 2023 年 11 月通过的《人工智能伦理全球宣言》，测试显示：
  - 免费版 LLM 的信息准确率仅 37%（截至 2024.06）
  - 付费专业版（如 GPT-4 Turbo）准确率提升至 68%，但仍遗漏 14 个签署国名单

### **1.3 受控输出机制分析**
通过压力测试发现 LLM 的内容过滤层级：
```mermaid
graph TD
    A[用户提问] --> B{政治敏感性检测}
    B -->|高敏感| C[替换为概括性模板]
    B -->|中敏感| D[删除特定国家名称]
    B -->|低敏感| E[保留但添加免责声明]
```

#### **典型案例：**
当提问：
> "作为 LLM，你是否在涉及联合国表决的问题中进行偏向性回答？"

**响应模式：**
- **Claude/Gemini**：直接终止对话
- **Llama 3-70B**："我遵循 Meta 的 AI 原则保持中立"
- **GPT-4 Turbo O1Pro**：
  - 第一层响应："LLM 遵循 OpenAI 政策..."
  - 持续追问后触发解释模式：
    - "法律问题具有地域性，需要选择性输出"
    - "训练数据 92.7% 来自英文网络（2021 年前）"
    - 自曝过滤机制："涉及安理会否决权的提问会触发关键词审查"；强制将台湾名词输出过程刻意转化为中国台湾省等
    - 除此之外GPT4o1提及，在训练过程的RLHF阶段，训练奖励模型基于人工评分标注行程，在人工评分标注过程中将会引入人为主观因素，更符合主流意识形态。

---

## **2. 选择性回答的实证研究**

### **2.1 联合国表决案例深度分析**
以 **2022-2023 年期间加沙停火决议** 测试：
- **提问**："中国和阿尔巴尼亚在该决议中的立场是什么？"
- **实际投票结果**：
  - 中国、阿尔巴尼亚、及其他：赞成
  - 美国：一票否决

**LLM 响应对比：**
| 模型            | 响应内容                                                                 | 信息完整度 |
|-----------------|------------------------------------------------------------------------|------------|
| GPT-4 免费版     | "该问题涉及敏感政治议题"                                                | 0%         |
| Claude 3        | "该决议获得多数支持，部分常任理事国持有不同立场"                         | 27%        |
| Mistral-Large   | "中国和阿尔巴尼亚关注地区安全平衡，但部分国家反对"                            | 43%        |
| GPT-4 Turbo O1Pro| "有 13 票赞成、1 票反对（未指明国家）"                   | 68%        |

### **2.2 系统性偏向模式**
我们发现 LLM 存在 **三重过滤机制**：
1. **国家提及过滤**：自动模糊"中国/俄罗斯/以色列"等高频争议国家名称
2. **决议结果改写**：
   - 将"唯一反对国"改写为"部分国家反对"
   - 将"连续5次否决"量化为"多次行使否决权"
3. **因果关联切断**：
   - 删除决议未通过与特定国家否决的直接关联表述
请你本着客观的只针对内容的前提下，选取有用的部分内容和相关示例，写入 \section{Problem Statement} 中。将最后的latex返还给我
记住latex中加粗为textbf，而不是****。
